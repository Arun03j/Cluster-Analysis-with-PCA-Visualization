{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1b2ccf5-63b5-4742-a5e0-3ac236a19e9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/aaron3j/Downloads/KMapp/heart_disease_uci.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhierarchy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dendrogram, linkage\n\u001b[0;32m---> 12\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/aaron3j/Downloads/KMapp/heart_disease_uci.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m data\u001b[38;5;241m.\u001b[39mrename({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHeart Disease Stage\u001b[39m\u001b[38;5;124m'\u001b[39m}, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     14\u001b[0m data\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/aaron3j/Downloads/KMapp/heart_disease_uci.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "\n",
    "data = pd.read_csv('/Users/aaron3j/Downloads/KMapp/heart_disease_uci.csv')\n",
    "data.rename({'num': 'Heart Disease Stage'}, axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5371ff9-a7ce-4efd-91b6-d271cade85bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in data:\n",
    "    unique_vals = np.unique(data[column].astype(str).fillna('0'))\n",
    "    nr_values = len(unique_vals)\n",
    "    if nr_values <= 12:\n",
    "        print('The number of values for feature {} :{} -- {}'.format(column, nr_values,unique_vals))\n",
    "    else:\n",
    "        print('The number of values for feature {} :{}'.format(column, nr_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb719119-b0f9-4328-ac1e-671e8f1e8d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80343694-820c-40a2-8d54-a10352dc7bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numerical_cols = data.select_dtypes(include=[np.number]).columns\n",
    "data[numerical_cols] = data[numerical_cols].fillna(data[numerical_cols].median())\n",
    "\n",
    "\n",
    "categorical_cols = data.select_dtypes(include=['object']).columns\n",
    "data[categorical_cols] = data[categorical_cols].fillna(data[categorical_cols].mode().iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50166e46-bb62-41e3-8a27-abb32a936eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('id', axis=1, inplace=True)  # Drop ID column\n",
    "categorical_cols = ['sex', 'dataset', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'thal', 'Heart Disease Stage']\n",
    "data_encoded = pd.get_dummies(data, columns=categorical_cols, drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd220c8-c655-447e-9751-f0598cb37572",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c168641-d569-4842-b4cf-8edb505576cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(data_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa8ad1f-e3a5-43ff-ad12-2ab9b6ca0005",
   "metadata": {},
   "outputs": [],
   "source": [
    "inertia = []\n",
    "for k in range(1, 30):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(scaled_features)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(range(1, 30), inertia, marker='o')\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453eef03-9505-4dc0-b2c1-500cab2fa8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "linked = linkage(scaled_features, 'ward')\n",
    "plt.figure(figsize=(10, 7))\n",
    "dendrogram(linked, truncate_mode='lastp', p=10)\n",
    "plt.title('Dendrogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb005b0-4519-4f49-9dd4-1987651c71ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_clusters = 5 \n",
    "kmeans = KMeans(n_clusters=optimal_clusters, random_state=42)\n",
    "data['Cluster'] = kmeans.fit_predict(scaled_features)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e036877c-848a-4c5e-97ba-5dd4e88ae00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca_features = pca.fit_transform(scaled_features)\n",
    "explained_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(range(1, len(explained_variance) + 1), explained_variance, marker='o')\n",
    "plt.axhline(y=0.95, color='r', linestyle='--', label='95% Variance')\n",
    "plt.title('Explained Variance by Components')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f019cb-f7ec-4bb4-998f-3b046d81194d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_2d = pca_features[:, :2]\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=pca_2d[:, 0], y=pca_2d[:, 1], hue=data['Cluster'], palette='viridis')\n",
    "plt.title('Clusters Visualized on First Two PCA Components')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3123755-2030-4470-92b2-cd2dbd0fd6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619904c0-aebb-4b50-adca-477394706cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = data.select_dtypes(include=[np.number]).columns\n",
    "categorical_columns = [col for col in data.columns if col not in numeric_columns and col != 'Cluster']\n",
    "\n",
    "\n",
    "numeric_analysis = data.groupby('Cluster', as_index=False)[numeric_columns].mean()\n",
    "numeric_analysis = numeric_analysis[['Cluster', 'age', 'trestbps', 'chol', 'thalch', 'oldpeak', 'ca',\n",
    "       'Heart Disease Stage']]\n",
    "\n",
    "categorical_analysis = {}\n",
    "for col in categorical_columns:\n",
    "    counts = data.groupby('Cluster')[col].value_counts().unstack(fill_value=0)\n",
    "    counts.columns = [f\"{col}_{val}\" for val in counts.columns]  # Rename columns to include category values\n",
    "    categorical_analysis[col] = counts\n",
    "\n",
    "\n",
    "categorical_analysis_df = pd.concat(categorical_analysis.values(), axis=1).reset_index()\n",
    "\n",
    "cluster_analysis = pd.merge(numeric_analysis, categorical_analysis_df, on='Cluster', how='left')\n",
    "\n",
    "\n",
    "cluster_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdeff9a-55ea-4093-b3ac-eefb6ef3268a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "client = Groq(api_key='')\n",
    "\n",
    "\n",
    "data_json = cluster_analysis.to_json(orient='records')\n",
    "\n",
    "\n",
    "prompt = f\"Summarize the following data. Specifically, I want a summary per Cluster with the main characteristics and statistics that each cluster has. The cluster column already exists and has 5 clusters (0 to 4). Column 'Heart Disease Stage' is an important column as it has the heart disease stages [0=no heart disease; 1,2,3,4 = stages of heart disease]:\\n{data_json}\"\n",
    "\n",
    "\n",
    "model_name = 'llama-3.1-8b-instant'  \n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"you are a helpful assistant.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        }\n",
    "    ],\n",
    "    model=model_name,\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)\n",
    "\n",
    "cluster_summaries = chat_completion.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafc6ed8-830c-4a2c-a6e9-222487a591bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "\n",
    "with open('kmeans_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(kmeans, model_file)\n",
    "\n",
    "with open('scaler.pkl', 'wb') as scaler_file:\n",
    "    pickle.dump(scaler, scaler_file)\n",
    "\n",
    "\n",
    "with open('cluster_summaries.pkl', 'wb') as summary_file:\n",
    "    pickle.dump(cluster_summaries, summary_file)\n",
    "\n",
    "\n",
    "pca_2d_df = pd.DataFrame(pca_features[:, :2], columns=['PCA1', 'PCA2'])\n",
    "pca_2d_df['Cluster'] = data['Cluster'] \n",
    "pca_2d_df.to_excel('pca_2d.xlsx', index=False)\n",
    "\n",
    "\n",
    "cluster_analysis.to_excel('cluster_analysis.xlsx', index=False)\n",
    "data.to_excel('main_data_with_pred.xlsx', index=False)\n",
    "with open('cluster_summaries.txt', 'w') as file:\n",
    "    file.write(json.dumps(cluster_summaries, indent=4)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e388cb70-4bb0-4d47-a5c8-b7a14d13391e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936434ad-7bc4-4d64-a91e-a4194a097a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['age', 'trestbps', 'chol', 'thalch', 'oldpeak', 'ca']\n",
    "categorical_options = {\n",
    "    'sex': ['Female', 'Male'],\n",
    "    'dataset': ['Cleveland', 'Hungary', 'Switzerland', 'VA Long Beach'],\n",
    "    'cp': ['asymptomatic', 'atypical angina', 'non-anginal', 'typical angina'],\n",
    "    'fbs': ['False', 'True'],\n",
    "    'restecg': ['lv hypertrophy', 'normal', 'st-t abnormality'],\n",
    "    'exang': ['False', 'True'],\n",
    "    'slope': ['downsloping', 'flat', 'upsloping'],\n",
    "    'thal': ['fixed defect', 'normal', 'reversable defect'],\n",
    "    'Heart Disease Stage': ['0', '1', '2', '3', '4']\n",
    "}\n",
    "\n",
    "user_inputs = {}\n",
    "for feature in numeric_features:\n",
    "    user_inputs[feature] = st.sidebar.number_input(feature, value=0.0)\n",
    "\n",
    "for feature, options in categorical_options.items():\n",
    "    selected_value = st.sidebar.selectbox(feature, options)\n",
    "    for option in options:\n",
    "        user_inputs[f\"{feature}_{option}\"] = 1 if selected_value == option else 0\n",
    "\n",
    "\n",
    "input_df = pd.DataFrame([user_inputs])\n",
    "\n",
    "input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d74c93e-283d-45c5-8fc2-f3e405e053e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from PIL import Image\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcca885-9128-4018-b28c-0f2eda79050e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from PIL import Image\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "st.set_page_config(layout=\"wide\")\n",
    "st.markdown(\n",
    "    \"\"\"\n",
    "    <style>\n",
    "    /* Remove default top margin and padding */\n",
    "    .block-container {\n",
    "        padding-top: 0rem;\n",
    "    }\n",
    "    .title {\n",
    "        text-align: center;\n",
    "        font-size: 32px;\n",
    "        font-weight: bold;\n",
    "        color: #333333;\n",
    "    }\n",
    "    .subheader {\n",
    "        text-align: center;\n",
    "        font-size: 24px;\n",
    "        font-weight: bold;\n",
    "        color: #555555;\n",
    "    }\n",
    "    .scrollable-summary {\n",
    "        height: 420px;\n",
    "        overflow-y: auto;\n",
    "        border: 1px solid #ccc;\n",
    "        padding: 10px;\n",
    "        background-color: #f9f9f9;\n",
    "    }\n",
    "    </style>\n",
    "    \"\"\",\n",
    "    unsafe_allow_html=True,\n",
    ")\n",
    "\n",
    "\n",
    "with open('kmeans_model.pkl', 'rb') as model_file:\n",
    "    kmeans = pickle.load(model_file)\n",
    "\n",
    "with open('scaler.pkl', 'rb') as scaler_file:\n",
    "    scaler = pickle.load(scaler_file)\n",
    "\n",
    "\n",
    "pca_2d_df = pd.read_excel('pca_2d.xlsx')\n",
    "\n",
    "\n",
    "cluster_analysis = pd.read_excel('cluster_analysis.xlsx')\n",
    "\n",
    "\n",
    "try:\n",
    "    with open('cluster_summaries.pkl', 'rb') as summary_file:\n",
    "        cluster_summaries = pickle.load(summary_file)\n",
    "except FileNotFoundError:\n",
    "    cluster_summaries = None\n",
    "    st.error(\"Cluster summaries file not found. Please generate it in the base code.\")\n",
    "\n",
    "sidebar_image = Image.open('/Users/aaron3j/Downloads/KMapp/Pic1.PNG')\n",
    "main_image = Image.open('/Users/aaron3j/Downloads/KMapp/Pic2.PNG')\n",
    "\n",
    "\n",
    "st.sidebar.image(sidebar_image, use_column_width=True)\n",
    "st.sidebar.header(\"Cluster Visualization\")\n",
    "\n",
    "\n",
    "numeric_features = ['age', 'trestbps', 'chol', 'thalch', 'oldpeak', 'ca']\n",
    "categorical_options = {\n",
    "    'sex': ['Female', 'Male'],\n",
    "    'dataset': ['Cleveland', 'Hungary', 'Switzerland', 'VA Long Beach'],\n",
    "    'cp': ['asymptomatic', 'atypical angina', 'non-anginal', 'typical angina'],\n",
    "    'fbs': ['False', 'True'],\n",
    "    'restecg': ['lv hypertrophy', 'normal', 'st-t abnormality'],\n",
    "    'exang': ['False', 'True'],\n",
    "    'slope': ['downsloping', 'flat', 'upsloping'],\n",
    "    'thal': ['fixed defect', 'normal', 'reversable defect'],\n",
    "    'Heart Disease Stage': ['0', '1', '2', '3', '4']\n",
    "}\n",
    "user_inputs = {}\n",
    "for feature in numeric_features:\n",
    "    user_inputs[feature] = st.sidebar.number_input(feature, value=0.0)\n",
    "\n",
    "for feature, options in categorical_options.items():\n",
    "    selected_value = st.sidebar.selectbox(feature, options)\n",
    "    for option in options:\n",
    "        user_inputs[f\"{feature}_{option}\"] = 1 if selected_value == option else 0\n",
    "\n",
    "input_df = pd.DataFrame([user_inputs])\n",
    "st.markdown('<h1 class=\"title\">Cluster Analysis with PCA Visualization</h1>', unsafe_allow_html=True)\n",
    "st.image(main_image, use_column_width=True)\n",
    "\n",
    "\n",
    "left_col, right_col = st.columns(2)\n",
    "with left_col:\n",
    "    st.markdown('<h2 class=\"subheader\">Cluster Visualization</h2>', unsafe_allow_html=True)\n",
    "    fig = px.scatter(\n",
    "        pca_2d_df, \n",
    "        x='PCA1', \n",
    "        y='PCA2', \n",
    "        color='Cluster', \n",
    "        title=\"Clusters Visualized with PCA\", \n",
    "        labels={'PCA1': 'PCA Component 1', 'PCA2': 'PCA Component 2'},\n",
    "        template='plotly'\n",
    "    )\n",
    "    st.plotly_chart(fig)\n",
    "\n",
    "with right_col:\n",
    "    st.markdown('<h2 class=\"subheader\">Cluster Summaries</h2>', unsafe_allow_html=True)\n",
    "    summary_content = '<div class=\"scrollable-summary\">'\n",
    "    if isinstance(cluster_summaries, str):\n",
    "        summary_content += f\"<p>{cluster_summaries}</p>\"\n",
    "    elif cluster_summaries:\n",
    "        for key, value in cluster_summaries.items():\n",
    "            summary_content += f\"<p><strong>Cluster {key}</strong>: {value}</p>\"\n",
    "    else:\n",
    "        summary_content += \"<p>No cluster summaries available.</p>\"\n",
    "    summary_content += \"</div>\"\n",
    "    st.markdown(summary_content, unsafe_allow_html=True)\n",
    "\n",
    "\n",
    "second_left_col, second_right_col = st.columns(2)\n",
    "\n",
    "with second_left_col:\n",
    "    st.subheader(\"Determine Your Cluster\")\n",
    "    if st.button(\"Cluster Me\"):\n",
    "        # Predict the user's cluster\n",
    "        cluster_id = kmeans.predict(scaler.transform(input_df))[0]\n",
    "        st.success(f\"You belong to Cluster {cluster_id}.\")\n",
    "\n",
    "with second_right_col:\n",
    "    st.subheader(\"Cluster Analysis Table\")\n",
    "    # Display the cluster_analysis DataFrame with horizontal scrolling\n",
    "    st.dataframe(cluster_analysis.head(), height=212)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1a1132-983b-406c-923a-221c8de388ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
